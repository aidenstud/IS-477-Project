
The data lifecycle we chose to relate our project to is the MSSP Data Lifecycle. We felt most comfortable using this lifecycle as a guiding framework since we work with it in other classes, such as Statistics 107 and 207. 
We began the project by researching data sets and formulating possible questions from there. We wanted to ensure that we could find quality data first to provide us with ample information to answer our research questions. To manage the data, we were able to store it in our repository. We discussed using Parquet files to store the data, but it was small enough for us to manage it in its original state.
To clean the data, we worked in Python to uncover potential logical errors and to improve the consistency of entries in the dataset. Our first step was to convert each variable into its appropriate variable type, since all the variables were originally objects. The bulk of the cleaning was us formatting whitespace and capitalization to make the data as uniform as possible.
After cleaning, we moved into descriptive analytics. Our first question on the most common delays and their causes was our foray into descriptive analytics, where we determined what the most likely delay causes were. We found that police and medical was the most common, but there was not specific information available on these incidents beyond the simple description.
We also explored whether more incidents increase ride time and whether rush hour travels experience longer travel times. These questions allowed us to delve deeper into descriptive and prescriptive analytics.
Finally, for the coding, ethics, and communication section of the lifecycle we used python/pandas to do our analysis. We chose a dataset containing rider information on the entire subway system, focusing on all lines and riders to avoid discrimination. The dataset does not provide information on individual riders either, protecting their privacy. Finally, we built our git repository to communicate our project.
